# Investigaci√≥n Memoria Vectorial - Proyecto Chi Evolution
## Fecha: 2025-02-03

---

## 1. COMPARATIVA DE BASES DE DATOS VECTORIALES

### üèÜ LanceDB
**Perfil:** Embedded, serverless, ideal para edge/m√≥vil

| Caracter√≠stica | Especificaci√≥n |
|----------------|----------------|
| Arquitectura | Embedded, serverless |
| Licencia | Apache 2.0 (Open Source) |
| Lenguaje | Rust (Python/JS bindings) |
| Escala Ideal | Hasta ~50M vectores |
| Latencia | <10ms local |
| Costo | Gratuito (self-hosted) |

**Features Clave:**
- ‚úÖ Zero-copy, versioning autom√°tico
- ‚úÖ GPU support para √≠ndices
- ‚úÖ Multimodal nativo (texto, im√°genes, video, point clouds)
- ‚úÖ Lance columnar format optimizado para ML
- ‚úÖ Sin servidor que gestionar
- ‚úÖ Integraci√≥n nativa con LangChain, LlamaIndex

**Casos de Uso Ideales:**
- Edge computing / IoT
- Aplicaciones m√≥viles
- Prototipos r√°pidos
- RAG local (ej. AnythingLLM lo usa por defecto)

---

### ü•à Chroma
**Perfil:** Python-first, ideal para prototipado RAG

| Caracter√≠stica | Especificaci√≥n |
|----------------|----------------|
| Arquitectura | Client-Server o Embedded |
| Licencia | Apache 2.0 (Open Source) |
| Lenguaje | Python |
| Escala Ideal | Millones de vectores |
| Costo | Free self-hosted / $20-500/mo cloud |

**Features Clave:**
- ‚úÖ Deep LangChain integration
- ‚úÖ Comunidad activa
- ‚úÖ Setup simple (pip install chromadb)
- ‚úÖ Perfecto para RAG MVPs

**Casos de Uso Ideales:**
- Prototipado r√°pido
- Q&A chatbots
- Knowledge bases internas
- Aplicaciones con datos cambiantes frecuentemente

---

### ü•â Pinecone
**Perfil:** Managed cloud, zero-ops, enterprise

| Caracter√≠stica | Especificaci√≥n |
|----------------|----------------|
| Arquitectura | Fully Managed Cloud |
| Licencia | Proprietary |
| Escala Ideal | Billones de vectores |
| Latencia | 5-10ms |
| Costo | $70-1,200/mo |

**Features Clave:**
- ‚úÖ Zero-ops (sin servidores que gestionar)
- ‚úÖ Enterprise features (RBAC, encryption)
- ‚úÖ Hybrid search avanzado
- ‚úÖ Metadata filtering eficiente

**Casos de Uso Ideales:**
- Producci√≥n enterprise
- E-commerce real-time
- Startups que necesitan escalar r√°pido
- Equipos sin capacidad DevOps

---

### Otras Opciones

| Base de Datos | Arquitectura | Mejor Para | Notas |
|---------------|--------------|------------|-------|
| **Milvus** | Distributed, Client-Server | Billones de vectores, self-hosted | Open source, alta tunabilidad |
| **Weaviate** | Vector-native DB | GraphQL queries, modular | Open source, schema flexible |
| **Qdrant** | Rust-based | Filtrado h√≠brido, rust ecosystem | Open source, alta performance |
| **FAISS** | Library (Meta) | Investigaci√≥n, casos espec√≠ficos | No es DB completa |

---

## 2. RECOMENDACI√ìN PARA OPENCLAW/CHI

### Opci√≥n Primaria: **LanceDB**

**Razones:**
1. ‚úÖ **Embeddable:** Sin servidor externo, reduce complejidad
2. ‚úÖ **Rust-native:** Aligned con arquitectura moderna
3. ‚úÖ **Zero-copy:** Eficiente en memoria
4. ‚úÖ **Versioning:** Historial de cambios sin infra extra
5. ‚úÖ **Costo:** 100% gratuito, sin vendor lock-in
6. ‚úÖ **Integraci√≥n:** APIs Python/JS/REST disponibles

**Trade-off:** Limitado a ~50M vectores (suficiente para memoria conversacional personal)

---

### Alternativa: **Chroma**
Si se necesita:
- Mayor comunidad/ecosistema
- Integraci√≥n nativa con LangChain m√°s madura
- Opci√≥n cloud gestionada posteriormente

---

## 3. ESTRATEGIA DE EMBEDDINGS

### Opciones Analizadas

| Modelo | Dimensi√≥n | Idiomas | Calidad | Costo | Hosting |
|--------|-----------|---------|---------|-------|---------|
| **OpenAI text-embedding-3** | 1536-3072 | 100+ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $0.13/1M tokens | API |
| **BGE-M3** | 1024 | 100+ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Gratis | Local |
| **BGE-large-en-v1.5** | 1024 | EN | ‚≠ê‚≠ê‚≠ê‚≠ê | Gratis | Local |
| **E5-mistral** | 4096 | 100+ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Gratis | Local |
| **Nomic-embed** | 768 | 100+ | ‚≠ê‚≠ê‚≠ê‚≠ê | Gratis | Local |

---

### üèÜ Recomendaci√≥n: **BGE-M3**

**Por qu√©:**
1. ‚úÖ **Multi-linguality:** 100+ idiomas
2. ‚úÖ **Multi-granularity:** Input hasta 8192 tokens
3. ‚úÖ **Multi-functionality:** Dense + Lexical + Multi-vector (ColBERT)
4. ‚úÖ **SOTA:** Supera OpenAI v3 en benchmarks multiling√ºes
5. ‚úÖ **Gratuito:** Sin costos de API
6. ‚úÖ **Tama√±o:** Modelo base manejable (~2GB)

**Caracter√≠sticas √∫nicas:**
- **Dense retrieval:** Embedding tradicional
- **Sparse retrieval:** Lexical matching tipo BM25
- **Multi-vector:** ColBERT-style late interaction

---

### Alternativas:

**OpenAI text-embedding-3:**
- ‚úÖ M√°s simple, sin infra local
- ‚ùå Costo continuo
- ‚ùå Dependencia de terceros

**E5-mistral:**
- ‚úÖ Excelente calidad
- ‚ùå Mayor tama√±o (~20GB)
- ‚ùå Requiere m√°s recursos

---

## 4. ESQUEMA DE DATOS √ìPTIMO PARA MEMORIA CONVERSACIONAL

### Propuesta de Schema

```json
{
  "id": "uuid",
  "conversation_id": "uuid",
  "session_id": "string",
  "timestamp": "datetime",
  "role": "user|assistant|system|tool",
  "content": "string",
  "content_type": "text|image|audio|code",
  "embedding": "vector[1024]",
  "metadata": {
    "importance_score": "float 0-1",
    "topic_tags": ["string"],
    "emotional_sentiment": "string",
    "entities": ["string"],
    "action_items": ["string"],
    "referenced_messages": ["uuid"]
  },
  "context_window": {
    "previous_messages": ["uuid"],
    "related_memories": ["uuid"]
  },
  "retention": {
    "last_accessed": "datetime",
    "access_count": "int",
    "decay_factor": "float"
  }
}
```

---

### Estrategias de Organizaci√≥n

#### A. Jerarqu√≠a de Memoria

```
Working Memory (Contexto inmediato)
    ‚Üì (consolidaci√≥n)
Short-term Memory (√öltimas 24-48h)
    ‚Üì (importancia ‚â• threshold)
Long-term Memory (Todo almacenado)
    ‚Üì (acceso frecuente)
Core Memories (Identidad/preferencias)
```

#### B. Indexaci√≥n

1. **√çndice temporal:** Para recuperar conversaciones recientes
2. **√çndice sem√°ntico:** Para similaridad de contenido
3. **√çndice de entidades:** Para menciones de personas/lugares
4. **√çndice de t√≥picos:** Para agrupaci√≥n tem√°tica

#### C. Consolidaci√≥n

- **Nightly job:** Comprimir conversaciones del d√≠a en summary
- **Weekly job:** Identificar patrones y actualizar core memories
- **Monthly job:** Archivar mem√≥rias de bajo acceso

---

## 5. INTEGRACI√ìN CON OPENCLAW

### Arquitectura Propuesta

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    OpenClaw Agent                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Memory Mgr  ‚îÇ‚Üê‚Üí‚îÇ LanceDB (FS) ‚îÇ‚Üê‚Üí‚îÇ BGE-M3 Embed ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚Üë                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                     ‚îÇ
‚îÇ  ‚îÇ Context Comp ‚îÇ                                     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de Recuperaci√≥n

1. **Query embedding:** BGE-M3 codifica la consulta actual
2. **B√∫squeda h√≠brida:** LanceDB busca en dense + sparse
3. **Reranking:** Modelo ligero reordena resultados
4. **Context assembly:** Ensamblar ventana de contexto
5. **Compresi√≥n:** LLMLingua comprime si es necesario

---

## 6. IMPLEMENTACI√ìN SUGERIDA

### Fase 1: B√°sica
- LanceDB embedded
- BGE-M3 local
- Recuperaci√≥n sem√°ntica simple
- Ventana de contexto fija

### Fase 2: Avanzada
- Memoria jer√°rquica
- Consolidaci√≥n autom√°tica
- Filtrado h√≠brido
- Compresi√≥n de contexto

### Fase 3: Inteligente
- Importancia autom√°tica
- Clustering de t√≥picos
- Predicci√≥n de necesidades
- Memoria proactiva

---

## 7. COSTOS ESTIMADOS

### Opci√≥n Local (Recomendada)
| Componente | Costo |
|------------|-------|
| LanceDB | $0 |
| BGE-M3 | $0 (infra local) |
| Almacenamiento | ~$5/mes (SSD) |
| **Total** | **~$5/mes** |

### Opci√≥n Cloud
| Componente | Costo |
|------------|-------|
| Pinecone | $70/mo m√≠nimo |
| OpenAI Embeddings | ~$10/mo (uso moderado) |
| **Total** | **~$80/mes** |

---

## 8. CONCLUSIONES

1. **LanceDB** es ideal para OpenClaw: embedded, sin servidor, eficiente
2. **BGE-M3** supera a OpenAI en calidad multiling√ºe y es gratuita
3. **Esquema jer√°rquico** (working/short/long/core) optimiza retrieval
4. **H√≠brido dense+sparse** ofrece mejor recuperaci√≥n que solo embeddings
5. **Consolidaci√≥n peri√≥dica** mantiene memoria relevante y manejable

---

*Documento generado para Proyecto Chi Evolution - Fase 1*
